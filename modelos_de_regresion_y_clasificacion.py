# -*- coding: utf-8 -*-
"""Modelos de regresion y clasificacion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s8MLw2WTZMgXJ6JZaIxPcAEaDj-GWaKC

# Modelo de Regresion
## Librerias utilizadas

1.- numpy

2.- pandas

3.- scikit-learn

---
## Funciones y metodos

1.- np.random.seed(42)

Inicializa el generador de números aleatorios con una semilla fija (42 en este caso) para asegurar que los resultados sean reproducibles cada vez que se ejecute el código.

2.- np.random.randint

Genera números enteros aleatorios dentro de un rango especificado. Aquí se usa para crear valores aleatorios para las variables age, experience, education y hours_per_week.

3.- np.random.normal

Genera valores aleatorios de una distribución normal. Aquí se usa para añadir ruido aleatorio a la variable salary para simular datos más realistas.

4.- pd.Dataframe

Crea un DataFrame de pandas, que es una estructura de datos similar a una tabla en la que se pueden almacenar y manipular datos de forma eficiente.

5.- train_test_split(X, y, test_size=0.2, random_state=42)

Divide los datos en conjuntos de entrenamiento y prueba. X contiene las variables independientes y y la variable dependiente. El 20% de los datos se asigna al conjunto de prueba y el 80% al de entrenamiento. random_state=42 asegura la reproducibilidad de la división.

6.- LinearRegression()

Crea una instancia del modelo de regresión lineal.

7.- model.fit(X_train, y_train)

Entrena el modelo de regresión lineal utilizando los datos de entrenamiento. El modelo ajusta sus parámetros internos para minimizar el error en las predicciones de y en función de X.

8.- model.predict(X_test)

Utiliza el modelo entrenado para predecir los valores de y (salario) para los datos de prueba X_test.

9.- mean_squared_error(y_test, y_pred)

Calcula el error cuadrático medio entre los valores reales (y_test) y los valores predichos (y_pred). Un valor más bajo indica un mejor ajuste del modelo.

10.- r2_score(y_test, y_pred)

Calcula el coeficiente de determinación (R²) entre los valores reales (y_test) y los valores predichos (y_pred). Un valor cercano a 1 indica que el modelo explica bien la variabilidad de los datos.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Generar datos de regresión ficticios
np.random.seed(42)
regression_data = pd.DataFrame({
    'edad': np.random.randint(18, 71, 1000),
    'experiencia': np.random.randint(0, 51, 1000),
    'educacion': np.random.randint(1, 6, 1000),
    'horas_por_semana': np.random.randint(20, 61, 1000),
})
regression_data['salario'] = (regression_data['edad'] * 500 +
                             regression_data['experiencia'] * 1000 +
                             regression_data['educacion'] * 2000 +
                             regression_data['horas_por_semana'] * 100 +
                             np.random.normal(0, 10000, 1000)).astype(int)

# Paso 2: Preparar los datos
X = regression_data[['edad', 'experiencia', 'educacion', 'horas_por_semana']]
y = regression_data['salario']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Paso 3: Entrenar el modelo
model = LinearRegression()
model.fit(X_train, y_train)

# Paso 4: Evaluar el modelo
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

mse, r2
print(f"mse: {mse:.2f}")
print(f"r2: {r2:.2f}")
print(y_pred)
print(y)

"""# Modelo de Clasificacion

## Libreria utilizada
1.- pandas

2.- numpy

3.- sklearn

-----
## Funciones y metodos

1.- train_test_split:

-> Propósito: Divide los datos en dos conjuntos: uno para entrenar el modelo y otro para probarlo.

-> Uso: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

-> Parámetros:

  X: Las características (variables independientes).

  y: La variable objetivo (variable dependiente).

  test_size: Proporción de los datos que se destinarán al conjunto de prueba (por ejemplo, 0.2 significa 20%).

  random_state: Asegura que la división sea reproducible.

2.- RandomForestClassifier:

-> Propósito: Crea un modelo de clasificación basado en un conjunto de árboles de decisión.

-> Uso: model = RandomForestClassifier(random_state=42)

-> Parámetros:
random_state: Asegura que los resultados sean reproducibles.

3.- fit:

-> Propósito: Entrena el modelo utilizando los datos de entrenamiento.

-> Uso: model.fit(X_train, y_train)

-> Parámetros:
X_train: Las características del conjunto de entrenamiento.

y_train: La variable objetivo del conjunto de entrenamiento.

4.- predict:

-> Propósito: Realiza predicciones utilizando el modelo entrenado sobre un nuevo conjunto de datos.

-> Uso: y_pred = model.predict(X_test)

-> Parámetros:
X_test: Las características del conjunto de prueba.

5.- classification_report:

-> Propósito: Genera un informe con las principales métricas de clasificación como precisión, recall y f1-score.

-> Uso: report = classification_report(y_test, y_pred)

-> Parámetros:
y_test: Las etiquetas verdaderas del conjunto de prueba.
y_pred: Las etiquetas predichas por el modelo.

6.- confusion_matrix:

-> Propósito: Muestra una matriz de confusión que detalla las predicciones correctas e incorrectas.

-> Uso: conf_matrix = confusion_matrix(y_test, y_pred)

-> Parámetros:
y_test: Las etiquetas verdaderas del conjunto de prueba.
y_pred: Las etiquetas predichas por el modelo.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Paso 1: Generar datos de regresión y clasificar salarios
np.random.seed(42)
data = pd.DataFrame({
    'age': np.random.randint(18, 71, 1000),
    'experience': np.random.randint(0, 51, 1000),
    'education': np.random.randint(1, 6, 1000),
    'hours_per_week': np.random.randint(20, 61, 1000),
})
data['salary'] = (data['age'] * 500 +
                  data['experience'] * 1000 +
                  data['education'] * 2000 +
                  data['hours_per_week'] * 100 +
                  np.random.normal(0, 10000, 1000)).astype(int)

# Crear categorías de salario
bins = [0, 30000, 70000, np.inf]
labels = ['low', 'medium', 'high']
data['salary_category'] = pd.cut(data['salary'], bins=bins, labels=labels)

# Paso 2: Preparar los datos
X = data[['age', 'experience', 'education', 'hours_per_week']]
y = data['salary_category']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar el modelo
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Evaluar el modelo
y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

#report, conf_matrix
print(report)
print(conf_matrix)
print(y_pred)
print(y)